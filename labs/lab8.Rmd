---
title: "ETC 2420/5242 Lab 8 2016"
author: "Di Cook"
date: "Week 8"
output: pdf_document
---

```{r echo = FALSE, message = FALSE, warning = FALSE, warning = FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  error = FALSE, 
  echo = FALSE, 
  collapse = TRUE,
  comment = "#",
  fig.height = 4,
  fig.width = 8,
  fig.align = "center",
  cache = FALSE
)
library(knitr)
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(ggmap)
library(lubridate)
library(broom)
```

## Purpose

In this lab we will pull data together from multiple sources to answer the question whether adverse weather affects pedestrian traffic in Melbourne.

## Data

- Melbourne Open data portal contains pedestrian counts by hour for numerous sites around the city.
- The US Department of Commerce hosts a global data base on weather from ground stations collated by National Climatic Data Center.  

## Getting started

The list of weather stations is a small file. We will pull this data from the web first. And plot the locations for Australia on a map. Data can be found at this web site [http://www1.ncdc.noaa.gov/pub/data/ghcn/daily/](http://www1.ncdc.noaa.gov/pub/data/ghcn/daily/). Download the file `ghcnd-stations.txt`.

The `read_table` function from the `readr` package uses whitespace to guess where records start and end, very convenient. We also will only read the station information for Australia, that have ids starting with `ASN`. I used a text editor to find the line numbers of the start and end of these records. 

The `ggplot2` package has some basic maps included. To get the map of Australia we need to subset the world map based on the longitude and latitude of the station locations. Maps like this can be considered to be polygon data. We use these polygons as the background to the points corresponding to station locations. 

```{r echo=TRUE}
# Read stations data
stations <- read_table("../data/ghcnd-stations.txt", 
  col_names=c("ID", "lat", "lon", "elev", "state", "name", 
              "v1", "v2", "v3"), skip=353, n_max=17081)

oz <- map_data("world", xlim=range(stations$lon),
               ylim=range(stations$lat))
ggplot(oz, aes(x=long, y=lat)) + geom_path(aes(group=group)) + 
  coord_quickmap() + 
  geom_point(data=stations, aes(x=lon, y=lat), 
             colour="red", alpha=0.5)
```

We are next going to get the sensor locations, and plot these on a google map of Melbourne. You need to go to the [Melbourne Open Data Portal site](https://data.melbourne.vic.gov.au/Transport-Movement/Pedestrian-Sensor-Locations/ygaw-6rzq) and export the locations as a csv file.

```{r}
# Get pedestrian sensor locations
ped_loc <- read_csv("../data/Pedestrian_Sensor_Locations.csv")

melb <- get_map(location=c(mean(range(ped_loc$Longitude)),
                           mean(range(ped_loc$Latitude))), zoom=14)
ggmap(melb) + geom_point(data=ped_loc, 
                         aes(x=Longitude, y=Latitude), 
                         colour="#c51b7d", alpha=0.5, size=3)
```

Our next step is to extract the nearest weather station near downtown. 

```{r}
# Choose a weather station close to pedestrian sensors
melb_stns <- stations %>% filter(lon > min(ped_loc$Longitude), 
                                 lon < max(ped_loc$Longitude), 
                                 lat > min(ped_loc$Latitude),
                                 lat < max(ped_loc$Latitude))

ggmap(melb) + geom_point(data=ped_loc, 
                         aes(x=Longitude, y=Latitude), 
                         colour="#c51b7d", alpha=0.5, size=3) +
  geom_point(data=melb_stns, aes(x=lon, y=lat), 
             colour="#542788", size=6, shape=18)
```

## 

```{r}
# Read temp data
melb_ghcn <- read_csv("../data/melb_ghcn.csv")
melb_ghcn <- melb_ghcn %>% 
  select(stn_id, date, variable, value) %>%
  filter(variable %in% c("TMAX", "TMIN", "PRCP")) %>%
  mutate(year=substr(date, 1, 4), month_num=substr(date, 5, 6),
         mday=substr(date, 7, 8)) %>%
  mutate(date=as.Date(paste(mday, month_num, year, sep="-"),
                      format="%d-%m-%Y")) %>%
  mutate(mday=as.numeric(mday), month_num=as.numeric(month_num), 
         year=as.numeric(year), value = value/10)
melb_ghcn_wide <- melb_ghcn %>% spread(variable, value)
melb_ghcn_wide$PRCP[is.na(melb_ghcn_wide$PRCP)] <- 0
date_mis <- melb_ghcn_wide$date[is.na(melb_ghcn_wide$TMAX)]
melb_ghcn_wide$TMAX[is.na(melb_ghcn_wide$TMAX)] <-
  melb_ghcn_wide$TMAX[melb_ghcn_wide$date == date_mis-days(1)]
melb_ghcn_wide <- melb_ghcn_wide %>%
  mutate(high_prcp = ifelse(PRCP>5, "rain", "none"), 
         high_tmp = ifelse(TMAX>33, "hot", "not"), 
         low_tmp = ifelse(TMIN<6, "cold", "not"))
ggplot(melb_ghcn, aes(x=date, y=value)) + geom_point() + facet_wrap(~variable)

# Read sensor counts
ped_sub <- read_csv("../data/pedestrian_counts_sub.csv")
ped_sub <- ped_sub %>% 
  filter(year < 2015) %>%
  dplyr::arrange(sensor_id, date, time) 

# Combine data
ped_weather <- left_join(ped_sub, melb_ghcn_wide, by="date")

# Fit model
ped_weather$time <- factor(ped_weather$time)
ped_weather$high_prcp <- factor(ped_weather$high_prcp, levels=c("none", "rain"))
ped_weather$high_tmp <- factor(ped_weather$high_tmp, levels=c("not", "hot"))
ped_weather$low_tmp <- factor(ped_weather$low_tmp, levels=c("not", "cold"))

ped_weather_fs <- ped_weather %>% filter(sensor_name == "Flagstaff Station")
ped_weath_glm <- glm(count~day*time*month.x+year.x+TMAX+TMIN+PRCP,
                     data=ped_weather_fs, family=poisson(link="log"))
summary(ped_weath_glm)
ped_weath_aug <- augment(ped_weath_glm)
ped_weath_aug <- ped_weath_aug %>% mutate(.fitted_exp = exp(.fitted))
ped_weath_aug <- ped_weath_aug %>% mutate(time = as.numeric(time), 
  day = factor(day, levels=c("Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday")), 
  month.x = factor(month.x, levels=c("January", "February", "March", "April", 
                                     "May", "June", "July", "August", "September",
                                     "October", "November", "December")))

ggplot(ped_weath_aug, aes(x=time, y=.fitted_exp)) + geom_line() +
  facet_grid(month.x~day)

ggplot(filter(ped_weather, sensor_name=="Bourke Street Mall (South)"), 
       aes(x=time, y=count)) + geom_point() +
  facet_grid(month~day)

ped_weather_bsm <- ped_weather %>% filter(sensor_name == "Bourke Street Mall (South)")
ped_weath_bsm_glm <- glm(count~day*time*month+high_tmp+low_tmp+high_prcp,
                     data=ped_weather_bsm, family=poisson(link="log"))
summary(ped_weath_bsm_glm)
ped_weath_bsm_aug <- augment(ped_weath_bsm_glm)
ped_weath_bsm_aug <- ped_weath_bsm_aug %>% mutate(.fitted_exp = exp(.fitted))
ped_weath_bsm_aug <- ped_weath_bsm_aug %>% mutate(time = as.numeric(time), 
  day = factor(day, levels=c("Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday"), labels=c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")), 
  month = factor(month, levels=c("January", "February", "March", "April", 
                                     "May", "June", "July", "August", "September",
                                     "October", "November", "December"), 
                 labels=c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep",
                          "Oct", "Nov", "Dec")))

ggplot(ped_weath_bsm_aug, aes(x=time, y=.fitted_exp)) + 
  geom_point(aes(colour=interaction(high_prcp, high_tmp))) +
  facet_grid(month~day)
coef_bsm <- summary(ped_weath_bsm_glm)$coefficients
grep("prcp", rownames(coef_bsm))
grep("tmp", rownames(coef_bsm))
coef_bsm[42:44,]


# Find large residuals and explore reasons for these

```

## Reading


## Question 1


## Question 2


## Question 3


## Question 4


## TURN IN 

- Your `.Rmd` file
- Your Word (or pdf) file that results from knitting the Rmd.
- Make sure your group members are listed as authors, one person per group will turn in the report
- DUE: Wednesday after the lab, by 7am, loaded into moodle



## Resources

- https://data.melbourne.vic.gov.au/Transport-Movement/Pedestrian-Sensor-Locations/ygaw-6rzq
- Menne, M.J., I. Durre, B. Korzeniewski, S. McNeal, K. Thomas, X. Yin, S. Anthony, R. Ray, R.S. Vose, B.E.Gleason, and T.G. Houston, 2012: Global Historical Climatology Network - Daily (GHCN-Daily), Version 3. [indicate subset used following decimal, 
e.g. Version 3.12]. NOAA National Climatic Data Center. http://doi.org/10.7289/V5D21VHZ [9/9/2016].




